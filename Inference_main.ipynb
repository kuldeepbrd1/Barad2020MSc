{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference_main.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnbO31vmKLcY"
      },
      "source": [
        "import torch, os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvision as vision\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoLTyD7VOCoc"
      },
      "source": [
        "!git clone https://github.com/leoxiaobin/deep-high-resolution-net.pytorch\n",
        "HRNET_DIR =  '/content/deep-high-resolution-net.pytorch'\n",
        "if os.getcwd()!=HRNET_DIR:\n",
        "  os.chdir(HRNET_DIR)\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-zz-J9QOPcq"
      },
      "source": [
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "from pycocotools.coco import COCO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkJYeUTIOZm6"
      },
      "source": [
        "HRNET_DRIVE_DIR = '/content/drive/My Drive/Envisat/HRNet_regression/'\n",
        "\n",
        "\n",
        "if os.getcwd()!=HRNET_DRIVE_DIR:\n",
        "  os.chdir(HRNET_DRIVE_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfaD6BlrjDbo"
      },
      "source": [
        "def compute_bbox(img_size, uv_pt, margin = 5):\n",
        "        '''\n",
        "\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        uv_pt : TYPE\n",
        "            DESCRIPTION.\n",
        "        margin : TYPE, optional\n",
        "            DESCRIPTION. The default is 5.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            DESCRIPTION.\n",
        "\n",
        "        '''\n",
        "        #margin:percent : default  5% relaxed in w/h\n",
        "        relax_margin_u= (margin/100)*(max(uv_pt[0])-min(uv_pt[0]))\n",
        "        relax_margin_v= (margin/100)*(max(uv_pt[1])-min(uv_pt[1]))\n",
        "        u_max = max(uv_pt[0])+relax_margin_u if max(uv_pt[0])+relax_margin_u <=img_size[0] else img_size[0]\n",
        "        u_min = min(uv_pt[0])-relax_margin_u if min(uv_pt[0])-relax_margin_u >= 0 else 0\n",
        "        v_max = max(uv_pt[1])+relax_margin_v if max(uv_pt[1])+relax_margin_v <=img_size[1] else img_size[1]\n",
        "        v_min = min(uv_pt[1])-relax_margin_v if min(uv_pt[1])-relax_margin_v >= 0 else 0\n",
        "\n",
        "        return [u_min, v_min,  u_max, v_max]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IDqFiHlTJ-v"
      },
      "source": [
        "## Original Image and Annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k23PlG1AOi4K"
      },
      "source": [
        "img_id=10\n",
        "n_kps = 12\n",
        "img_path = f'/content/drive/My Drive/Envisat/data/Envisat_Set1/traj_test/test_traj_150m/0-999/image_{img_id}.jpg'\n",
        "img = Image.open(img_path,'r')\n",
        "gray = cv2.cvtColor(np.asarray(img),  cv2.COLOR_BGR2GRAY)\n",
        "img1 = np.zeros((gray.shape[0],gray.shape[1],3),dtype='uint8')\n",
        "img1[:,:,0] = gray \n",
        "img1[:,:,1] = gray \n",
        "img1[:,:,2] = gray \n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = fig.gca()\n",
        "ax.imshow(img1)\n",
        "img= Image.fromarray(img1)\n",
        "\n",
        "\n",
        "img_name = (img_path.split('/')[-1]).split('.')[0]\n",
        "cocofile = '/content/drive/My Drive/Envisat/data/Envisat_Set1/traj_test/test_traj_12pts_150m.json'\n",
        "coco = COCO(cocofile)\n",
        "annIds = coco.getAnnIds(imgIds = img_id)\n",
        "annotations = coco.loadAnns(annIds)\n",
        "bbox= {img_name: annotations[0]['bbox']}\n",
        "kps= {img_name: annotations[0]['keypoints']}\n",
        "coords = kps[img_name] \n",
        "kps_gt = np.zeros((n_kps,2))\n",
        "uv_pt = ([],[])\n",
        "for k in range(n_kps):\n",
        "  x = coords[3*k]\n",
        "  y =coords[3*k+1]\n",
        "  kps_gt[k,:] = [x,y]\n",
        "  uv_pt[0].append(x)\n",
        "  uv_pt[1].append(y)\n",
        "\n",
        "xyxy = compute_bbox((512,512),uv_pt) \n",
        "xywh = [ xyxy[0],xyxy[1], xyxy[2]-xyxy[0], xyxy[3]-xyxy[1]] \n",
        "bbox = {img_name: xywh} if n_kps==12 else bbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twkvg-oXMtt8"
      },
      "source": [
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLD_XTuBM_d-"
      },
      "source": [
        "Image Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeVzTGxUbewO"
      },
      "source": [
        "jitter = vision.transforms.ColorJitter(brightness= 0.4,contrast=0.4)#, saturation = 0.1, hue = 0.5)\n",
        "jitter = jitter(img)\n",
        "plt.imshow(jitter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYlDkPg41ZXa"
      },
      "source": [
        "Fake args Namespace Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfyZiTaWTNuM"
      },
      "source": [
        "class Namespace:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZYrgJQBfY4W"
      },
      "source": [
        "# Pose Inference: IPython"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aqlLyaGfVfZ"
      },
      "source": [
        "'''DO NOT JUDGE THIS CODE. \n",
        "   IT WAS WRITTEN AT 3 AM \n",
        "   DURING COVID-19 QUARANTINE\n",
        "'''\n",
        "\n",
        "from demo.sat_pose_inference import main as infer_kepyoints\n",
        "\n",
        "cfg_path = '/content/drive/My Drive/Envisat/HRNet_regression/experiments/EXP/EXP5_w32_256x256_adam_lr1e-3_ENVISAT+IC_imagenet.yaml'\n",
        "#cfg_path = '/content/drive/My Drive/Envisat/HRNet_regression/experiments/coco/hrnet/w32_256x256_adam_lr1e-3_ENVISAT-1_test.yaml'\n",
        "\n",
        "model_path = 'output/Envisat+IC/envisat_coco_envisat/pose_hrnet/EXP5_w32_256x256_adam_lr1e-3_ENVISAT+IC_imagenet/model_best.pth'\n",
        "#model_path = 'output/Envisat_Set1/coco/pose_hrnet/w32_256x256_adam_lr1e-3_ENVISAT-1/model_best.pth'\n",
        "\n",
        "\n",
        "''' Name you test data_set here. This helps segment tests in /output/sat_pose_inferences by folder of data_name'''\n",
        "data_name = 'beta_test'\n",
        "\n",
        "img_bgr = np.array(jitter)\n",
        "img_in0 =img_bgr[:, :, [2, 1, 0]]\n",
        "img_in1 = img_in0.copy();\n",
        "img_in = cv2.GaussianBlur(img_in1,(1,1),0)\n",
        "bbox_in = bbox\n",
        "\n",
        "\n",
        "args = Namespace(\n",
        "    cfg= cfg_path,\n",
        "    data_name = data_name,\n",
        "    logDir = 'log/',\n",
        "    outputDir = 'output/', \n",
        "    modelDir = '',\n",
        "    dataDir = '',\n",
        "    prevModelDir = '',\n",
        "    writeBoxFrames = False,\n",
        "    opts = ['TEST.MODEL_FILE', model_path],)\n",
        "\n",
        "\n",
        "\n",
        "#str_dir = f'/content/drive/My\\ Drive/Envisat/data/Envisat_Set1/traj_test/test_traj_150m/0-999/image_{img_id}.jpg'\n",
        "kps_pred, maxvals = infer_kepyoints(image= img_in, bbox= bbox_in, args = args)\n",
        "kps_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuT2rGdbqV1t"
      },
      "source": [
        "Show Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iuy_Uwh3NeTE"
      },
      "source": [
        "bbox_in"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKaGJl3k1qlI"
      },
      "source": [
        "error = kps_gt-kps_pred[0,:]\n",
        "dr_error = np.sqrt( error[:,0]**2 + error[:,1]**2 )\n",
        "mean_dr = np.mean(dr_error)\n",
        "median_dr = np.median(dr_error)\n",
        "print(f\" Mean Pixel Error: {mean_dr} px \\n Median Pixel Error: {median_dr} px \\n Max Pixel Error: {np.max(dr_error)} px in keypoint number {np.argmax(dr_error)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1vyhLfYslVx"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbCg-r92qVFB"
      },
      "source": [
        "\n",
        "output = f'output/sat_pose_inferences/envisat_coco_envisat/beta_test/poses/image_{img_id}_pose.jpg'\n",
        "#output = f'output/sat_pose_inferences/envisat_coco/beta_test/poses/image_{img_id}_pose.jpg'\n",
        "box = [int(coord) for coord in bbox[list(bbox)[0]]]\n",
        "img_out = Image.open(output)\n",
        "\n",
        "x1 = box [0] \n",
        "y1 = box[1]\n",
        "w = box[2]\n",
        "h = box[3]\n",
        "x2= box[2]+box[0]\n",
        "y2 = box[3]+box[1]\n",
        "\n",
        "cv2.rectangle(np.array(img),(x1,y1),(x2,y2), color = (0,255,0))\n",
        "\n",
        "img_crop = img_out.crop((x1,y1,x2,y2))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = fig.gca()\n",
        "\n",
        "#ax.imshow(np.asarray(img_crop))\n",
        "\n",
        "ax.imshow(img_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GL3ankPDvOr"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Wg5ScbqpjO"
      },
      "source": [
        "fig1 = plt.figure(figsize=(10,10))\n",
        "ax = fig.gca()\n",
        "ax2.imshow(img_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfV4PoskfkI-"
      },
      "source": [
        "# Pose Inference: CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U220YEzVj3KM"
      },
      "source": [
        "'''DO NOT JUDGE THIS CODE. \n",
        "   IT WAS WRITTEN AT 3 AM \n",
        "   DURING COVID-19 QUARANTINE\n",
        "'''\n",
        "\n",
        "\n",
        "str_dir = f'/content/drive/My\\ Drive/Envisat/data/Envisat_Set1/traj_test/test_traj_150m/0-999/image_{img_id}.jpg'\n",
        "with torch.cuda.device(0):\n",
        "  !python demo/sat_pose_inference_cmd.py --cfg experiments/coco/hrnet/w32_512x512_adam_lr1e-3_ENVISAT-1_traj_test.yaml \\\n",
        "      --data_name beta_test \\\n",
        "      --data_type image \\\n",
        "      --data_path $str_dir \\\n",
        "      --bbox demo/temp.json \\\n",
        "      TEST.MODEL_FILE output/Envisat_1/coco/pose_hrnet/w32_256x256_adam_lr1e-3_ENVISAT-1/model_best.pth \\\n",
        "\n",
        "\n",
        "output = f'output/sat_pose_inferences/coco/beta_test/poses/image_{img_id}_pose.jpg'\n",
        "box = bbox[list(bbox)[0]]\n",
        "img = Image.open(output)\n",
        "\n",
        "bbox = (box[0],box[1],box[2]+box[0],box[3]+box[1])\n",
        "cv2.rectangle(np.array(img),(bbox[0],bbox[1], bbox[2], bbox[3]))\n",
        "\n",
        "img_crop = img.crop(bbox)\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = fig.gca()\n",
        "ax.imshow(img)\n",
        "#ax.imshow(np.asarray(img_crop))\n",
        "fig1 = plt.figure(figsize=(10,10))\n",
        "ax1 = fig.gca()\n",
        "ax1.imshow(img)\n",
        "ax1.imshow(img_crop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoxYfmzAnJ02"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpUA0zneIBFe"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zccpc06pLTE"
      },
      "source": [
        "print(bbox)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqFsdB1MZANp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}